{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec29fa79c9a748608b849cdb630fbb86"
   },
   "source": [
    "# Online Trading Customer Attrition Risk Prediction using SparkML\n",
    "\n",
    "There are many users of online trading platforms and these companies would like to run analytics on and predict churn based on user activity on the platform. Since competition is rife, keeping customers happy so they do not move their investments elsewhere is key to maintaining profitability.\n",
    "\n",
    "In this notebook, we will leverage IBM Cloud Pak for Data to do the following:\n",
    "\n",
    "1. Ingest merged customer demographics and trading activity data\n",
    "2. Visualize the merged dataset to get a better understanding of the data and build hypotheses for prediction\n",
    "3. Leverage the SparkML library to build a classification model that predicts whether a customer has a propensity to churn\n",
    "4. Expose the SparkML classification model as a RESTful API endpoint for the end-to-end customer churn risk prediction and risk remediation application\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Table of Contents\n",
    "\n",
    "1. [Load the customer demographics and trading activity data](#load_data)\n",
    "2. [Load libraries](#load_libraries)\n",
    "3. [Visualize the customer demographics and trading activity data](#visualize)\n",
    "4. [Prepare data for building SparkML classification model](#prepare_data)\n",
    "5. [Train classification model and test model performance](#build_model)\n",
    "6. [Save and deploy the model using Watson Machine Learning](#save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5fa66512f0b4c99952c4512463fc453"
   },
   "source": [
    "### Quick set of instructions to work through the notebook\n",
    "\n",
    "If you are new to Notebooks, here's a quick overview of how to work in this environment.\n",
    "\n",
    "1. The notebook has 2 types of cells - markdown (text) such as this and code (further below). \n",
    "2. Each cell with code can be executed independently or together (see options under the Cell menu). When working in this notebook, we will be running one cell at a time because we need to make code changes to some of the cells.\n",
    "3. To run the cell, position cursor in the code cell and click the Run (arrow) icon. The cell is running when you see the * next to it. Some cells have printable output.\n",
    "4. Work through this notebook by reading the instructions and executing code cell by cell. Some cells will require modifications before you run them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6eae590-eadd-45da-90a3-9170eecee322"
   },
   "source": [
    "<a id=\"load_data\"></a>\n",
    "## 1. Load the customer and trading activity data\n",
    "[Top](#top)\n",
    "\n",
    "Data can be easily loaded within IBM Cloud Pak for Data using point-and-click functionality. The following image illustrates how to load the data from a database. The data set can be located by its name and inserted into the notebook as a pandas DataFrame as shown below.\n",
    "\n",
    "![insert_spark_dataframe.png](https://raw.githubusercontent.com/IBM/icp4d-customer-churn-classifier/master/doc/source/images/insert_spark_dataframe.png)\n",
    "\n",
    "The generated code comes up with a generic name and it is good practice to rename the dataframe to match the use case context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dec28eda0861427e828749fe188475af"
   },
   "source": [
    "<h3><font color=\"RED\">ACTION: Import the remote data set in the code cell below.</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c897555cf85c4cd6866a514bb7d71098"
   },
   "outputs": [],
   "source": [
    "# Use the find data 01/00 icon and under your remote data set\n",
    "# use \"Insert to code\" and \"pandas DataFrame\"\n",
    "# to import the input data into the notebook.\n",
    "\n",
    "# Add asset from file system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "999dbf855875473b803680a16fb4a5ad"
   },
   "outputs": [],
   "source": [
    "# After inserting the pandas DataFrame code above, change the following\n",
    "# df_data_# to match the variable used in the above code. df_churn_pd is used\n",
    "# later in the notebook.\n",
    "df_churn_pd = df_data_#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10cc9eb9e12f44558627ac52d4b49ef5"
   },
   "source": [
    "<a id=\"load_libraries\"></a>\n",
    "## 2. Load libraries\n",
    "[Top](#top)\n",
    "\n",
    "Use the commented code in the following cell to load all libraries needed to load, visualize, prepare the data and build ML models for our use case.\n",
    "\n",
    "<h3><font color=\"RED\">NOTE: if you install any of the required libraries here, you will have to restart the KERNEL and re-run code from the beginning of the notebook.</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7b7fde23af44e9dbab9bcf8435793bc"
   },
   "outputs": [],
   "source": [
    "# The following libraries are required for this notebook and should already be installed in the \n",
    "# kernel. If not, install them here. The versions listed have been tested to work with this notebook.\n",
    "\n",
    "# NOTE: if you do have to perform one or more of these installs, you MUST restart the kernel\n",
    "#!pip install --user pyspark==2.3.2\n",
    "#!pip install --user py4j==0.10.7\n",
    "#!pip install --user ibm-watson-machine-learning==1.0.44\n",
    "#!pip install --user brunel==2.3\n",
    "\n",
    "# check if libraries are loaded\n",
    "!pip freeze | grep -e pyspark -e py4j -e ibm-watson-machine-learning -e brunel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f4da5801fbb434a885f90afa7fad293"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, IndexToString\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import brunel\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43623fb6-b3a1-4686-81e6-0d214f34f9d3"
   },
   "source": [
    "<a id=\"visualize\"></a>\n",
    "## 3. Visualize the customer demographics and trading activity data\n",
    "[Top](#top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "254106c20ebb44f996fdbde960b74d2d"
   },
   "source": [
    "Data visualization is a key step in the data mining process that helps to better understand the data before it can be prepared for building ML models. In this notebook, we will use Brunel for data visualization.\n",
    "\n",
    "The Brunel Visualization Language is a highly succinct and novel language that defines interactive data visualizations based on tabular data. The language is well suited for both data scientists and business users. More information about Brunel Visualization: https://github.com/Brunel-Visualization/Brunel/wiki\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "291e2ea9-5f8f-4e8c-9d99-3e27e5ac47d8"
   },
   "source": [
    "### Churn risk count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26817012dab949fa90b88ea0860e1b29"
   },
   "outputs": [],
   "source": [
    "%brunel data('df_churn_pd') stack polar bar x(CHURNRISK) y(#count) color(CHURNRISK) bar tooltip(#all) :: width=300, height=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "048a9d13-f301-42d7-aaca-e12e751f988b"
   },
   "source": [
    "### Marital status count and churn risk percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d77f7c965344d52a7aa1fcd0b0dee4f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%brunel data('df_churn_pd') bar x(STATUS) y(#count) color(STATUS) tooltip(#all) | stack bar x(STATUS) y(#count) color(CHURNRISK: pink-orange-yellow) bin(STATUS) sort(STATUS) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed1e714d-3a23-4de6-bfaa-60b342258b40"
   },
   "source": [
    "### Churn risk count by total units traded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64d409033d02440c9dd31a3db40ff811"
   },
   "outputs": [],
   "source": [
    "%brunel data('df_churn_pd') stack bar x(TOTALUNITSTRADED:[0, 350]) y(#count) color(CHURNRISK: pink-gray-orange) sort(STATUS) label(#count) tooltip(#all) :: width=1200, height=350 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "815dedbd-d37a-41fc-8b64-aea05594d934"
   },
   "source": [
    "### Churn risk percentage by days since last trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14b8d1bc64774322a3633b052492d2ac"
   },
   "outputs": [],
   "source": [
    "%brunel data('df_churn_pd') stack bar x(DAYSSINCELASTTRADE) y(#count) color(CHURNRISK: pink-gray-orange) sort(STATUS) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cbe67fec89c4d0fa3628bf9c975acc6"
   },
   "source": [
    "<a id=\"prepare_data\"></a>\n",
    "## 4. Prepare data for building SparkML classification model\n",
    "[Top](#top)\n",
    "\n",
    "Data preparation is a very important step in machine learning model building. This is because the model can perform well only when the data it is trained on is good and well prepared. Hence, this step consumes the bulk of data scientists' time spent building models.\n",
    "\n",
    "During this process, we identify categorical columns in the dataset. Categories needed to be indexed, which means the string labels are converted to label indices. These label indices are encoded using One-hot encoding to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. This encoding allows algorithms which expect continuous features to use categorical features.\n",
    "\n",
    "Final step in the data preparation process is to assemble all the categorical and non-categorical columns into a feature vector. We use VectorAssembler for this. VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4145c2f8795b4eeb8a77fa723b7f0f8c"
   },
   "outputs": [],
   "source": [
    "# Defining the categorical columns \n",
    "categoricalColumns = ['GENDER', 'STATUS', 'HOMEOWNER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4224a5246be9492290bf899f596fb71c"
   },
   "outputs": [],
   "source": [
    "non_categoricalColumns = [c for c in df_churn_pd.columns if c not in categoricalColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ba14d867a604a078642a4a31ac0efd1"
   },
   "outputs": [],
   "source": [
    "print(non_categoricalColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "260270cede8d4d728bc1ec5b0bfdf6f5"
   },
   "outputs": [],
   "source": [
    "non_categoricalColumns.remove('CHURNRISK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88bd93315e584b148323d4ed46c3fa44"
   },
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f01bc58552094a17a12ece367b031ea6"
   },
   "outputs": [],
   "source": [
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    # Category Indexing with StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    \n",
    "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "    encoder = OneHotEncoder(inputCol=categoricalCol + \"Index\", outputCol=categoricalCol + \"classVec\")\n",
    "    \n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b45ec4dd924b4e6693511a9ac81bd373"
   },
   "outputs": [],
   "source": [
    "spark_df_churn = spark.createDataFrame(df_churn_pd)\n",
    "labelIndexer = StringIndexer(inputCol='CHURNRISK', outputCol='label').fit(spark_df_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b9d3c8469a14853871eb69e817e0c9a"
   },
   "outputs": [],
   "source": [
    "for colnum in non_categoricalColumns:\n",
    "    spark_df_churn = spark_df_churn.withColumn(colnum, spark_df_churn[colnum].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae5fc061bb0942429189c098070f113d"
   },
   "outputs": [],
   "source": [
    "# Transform all features into a vector using VectorAssembler\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + non_categoricalColumns\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6d5ea56e0714af2885317830f6814db"
   },
   "source": [
    "<a id=\"build_model\"></a>\n",
    "## 5. Train classification model and test model performance\n",
    "[Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71ef032cab7f4fc282a1e0020d2efc23"
   },
   "source": [
    "We instantiate a decision-tree based classification algorithm, namely, RandomForestClassifier. Next we define a pipeline to chain together the various transformers and estimators that were defined during the data preparation step. MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline or workflow.\n",
    "\n",
    "We split the original dataset into train and test datasets. We fit the pipeline to training data and apply the trained model on the test data and generate churn risk class prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83464fcd964341888c55da62017fcea8"
   },
   "outputs": [],
   "source": [
    "# Instantiate a random forest classifier, take the default settings\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "stages += [labelIndexer, assembler, rf, labelConverter]\n",
    "\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc659f09a398490f9f2627f3dba0d921"
   },
   "outputs": [],
   "source": [
    "# Split data into train and test datasets\n",
    "train, test = spark_df_churn.randomSplit([0.7,0.3], seed=100)\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "857f6ee080914a79826d60284d6ecad8"
   },
   "outputs": [],
   "source": [
    "# Build models\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9ee794aee65446b8a7b75950502211f"
   },
   "outputs": [],
   "source": [
    "results = model.transform(test)\n",
    "results = results.select(results[\"ID\"],results[\"CHURNRISK\"],results[\"label\"],results[\"predictedLabel\"],results[\"prediction\"],results[\"probability\"])\n",
    "results.toPandas().head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a435eeb6-1e7f-4dc4-9dd2-e786b37b7523"
   },
   "source": [
    "### Model results\n",
    "\n",
    "In a supervised classification problem such as churn risk classification, we have a true output and a model-generated predicted output for each data point. For this reason, the results for each data point can be assigned to one of four categories:\n",
    "\n",
    "1. True Positive (TP) - label is positive and prediction is also positive\n",
    "2. True Negative (TN) - label is negative and prediction is also negative\n",
    "3. False Positive (FP) - label is negative but prediction is positive\n",
    "4. False Negative (FN) - label is positive but prediction is negative\n",
    "\n",
    "These four numbers are the building blocks for most classifier evaluation metrics. A fundamental point when considering classifier evaluation is that pure accuracy (i.e. was the prediction correct or incorrect) is not generally a good metric. The reason for this is because a dataset may be highly unbalanced. For example, if a model is designed to predict fraud from a dataset where 95% of the data points are not fraud and 5% of the data points are fraud, then a naive classifier that predicts not fraud, regardless of input, will be 95% accurate. For this reason, metrics like precision and recall are typically used because they take into account the type of error. In most applications there is some desired balance between precision and recall, which can be captured by combining the two into a single metric, called the F-measure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5524c363615748b1ad4a2e58758ac88a"
   },
   "outputs": [],
   "source": [
    "print('Model Precision = {:.2f}.'.format(results.filter(results.label == results.prediction).count() / float(results.count())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "640e7715-328a-49c4-a3ab-f195bcf482e6"
   },
   "source": [
    "An added advantage of such tree-based classifiers is we can study feature importances and learn further about relative importances of features in the classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "926ffb14b0dd477186ef6067b2d8a271"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "res = model.transform(test)\n",
    "predictions = res.rdd.map(lambda pr: pr.prediction)\n",
    "labels = res.rdd.map(lambda pr: pr.label)\n",
    "predictionAndLabels = spark.sparkContext.parallelize(zip(predictions.collect(), labels.collect()))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Overall statistics\n",
    "print(\"Overall Statistics\")\n",
    "f_measure = metrics.accuracy\n",
    "print(\"Model F-measure = %s\\n\" % f_measure)\n",
    "\n",
    "# statistics by class\n",
    "print(\"Statistics by Class\")\n",
    "labels_itr = labels.distinct().collect()\n",
    "for label in sorted(labels_itr):\n",
    "    print(\"Class %s F-Measure = %s\" % (label, metrics.fMeasure(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79b9b40e7f4b4dff81a665a14e449bfe"
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "rfModel = model.stages[-2]\n",
    "\n",
    "features = df_churn_pd.columns\n",
    "importances = rfModel.featureImportances.values\n",
    "indices = np.argsort(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06b9e42506064d8e872d954ac0f82f5c"
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b',align='center')\n",
    "plt.yticks(range(len(indices)), (np.array(features))[indices])\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "033ef866-c233-4617-a172-d414155c86e6"
   },
   "source": [
    "Before we save the random forest classifier to repository, let us first evaluate the performance of a simple Naive Bayes classifier trained on the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da90dd4487444964b222efbf66e6c2dd"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "stages_nb = stages\n",
    "\n",
    "stages_nb[-2] = nb\n",
    "\n",
    "pipeline_nb = Pipeline(stages = stages_nb)\n",
    "\n",
    "# Build models\n",
    "model_nb = pipeline_nb.fit(train)\n",
    "results_nb = model_nb.transform(test)\n",
    "\n",
    "print('Naive Bayes Model Precision = {:.2f}.'.format(results_nb.filter(results_nb.label == results_nb.prediction).count() / float(results_nb.count())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adac54c5-2e9e-4cbc-9e93-a8dfdd514b03"
   },
   "source": [
    "As you can see from the results above, Naive Bayes classifier does not perform well. Random forest classifier shows high F-measure upon evaluation and shows strong performance. Hence, we will save this model to the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "027f4574b0d14614816a2d1d9946f7a3"
   },
   "source": [
    "<a id=\"save_model\"></a>\n",
    "## 6. Save and deploy the model using Watson Machine Learning\n",
    "[Top](#top)\n",
    "\n",
    "The Watson Machine Learning client should be available on your IBM Cloud Pak for Data platform. \n",
    "\n",
    "<h3><font color=\"RED\">ACTION: Obtain the URL, username and password for your IBM Cloud Pak for Data instance from your IBM Cloud Pak for Data administrator and provide the values in the code cell below.</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fb7f1ed8f2f400c809117f3dfd18d75"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "# get URL, username and password from your IBM Cloud Pak for Data administrator\n",
    "wml_credentials = {\n",
    "  \"url\": \"https://X.X.X.X\",\n",
    "  \"username\": \"*****\",\n",
    "  \"password\": \"*****\",\n",
    "  \"instance_id\": \"wml_local\",\n",
    "  \"version\": \"3.5\"\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "print(client.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12287d99-290d-4ad8-828b-ac25b562afe2"
   },
   "source": [
    "### Set default space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b35cfd0eae244ee2813ef1ff0e001077"
   },
   "source": [
    "In order to deploy a model, you would have to create different deployment spaces and deploy your models there. You can list all the spaces using the .list() function, or you can create new spaces by going to CP4D menu on top left corner --> analyze --> analytics deployments --> New Deployment Space. Once you know which space you want to deploy in, simply use the ID of the space as argument for .set.default_space() function below.\n",
    "\n",
    "<h3><font color=\"RED\">ACTION: Provide the name of your deployment space in the code cell below.</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dc0d0d440a040e29893d2d17f9dcc63"
   },
   "outputs": [],
   "source": [
    "#Insert the name of your deployment space here:\n",
    "DEPLOYMENT_SPACE_NAME = 'INSERT_YOUR_DEPLOYMENT_SPACE_NAME_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c985118fc7094fc29d033dd7b8326813"
   },
   "source": [
    "The deployment space ID will be looked up based on the name specified above. If you do not receive a space ID as an output to the next cell, verify that you have provided the correct deployment space name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88cfba8d60ef4ff5aa4b51a1c58fb509"
   },
   "source": [
    "<h3><font color=\"RED\">NOTE: Do not proceed until you have created a deployment space and this next cell runs successfully and returns the space_id.</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20e11ed4d27a4789a99f9007607b37ad"
   },
   "outputs": [],
   "source": [
    "# Be sure to update the name of the space with the one you want to use.\n",
    "client.spaces.list()\n",
    "all_spaces = client.spaces.get_details()['resources']\n",
    "space_id = None\n",
    "for space in all_spaces:\n",
    "    if space['entity']['name'] == DEPLOYMENT_SPACE_NAME:\n",
    "        space_id = space[\"metadata\"][\"id\"]\n",
    "        print(\"\\nDeployment Space ID: \", space_id)\n",
    "\n",
    "if space_id is None:\n",
    "    print(\"WARNING: Your space does not exist. Create a deployment space before proceeding to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e12f9e159610453a8c9ea6fa8ea1259f"
   },
   "source": [
    "<h3><font color=\"RED\">ACTION: Set the ID for your Deployment space as the default_space in the method below:</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcb81fd29a7d4bcf865d05c7d7965a15"
   },
   "outputs": [],
   "source": [
    "# Now set the default space to the ID for your deployment space. If this is successful, you will see a 'SUCCESS' message.\n",
    "client.set.default_space('INSERT_YOUR_DEPLOYMENT_SPACE_ID_HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4527a2c762946ab82e524b69ce67a88"
   },
   "outputs": [],
   "source": [
    "# Use this cell to do any cleanup of previously created models and deployments\n",
    "#client.deployments.delete('<GUID of the deployment>')\n",
    "#client.repository.delete('<ID of the model>')\n",
    "\n",
    "client.deployments.list()\n",
    "client.repository.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8eb34d06f694f388952ccb75472715d"
   },
   "outputs": [],
   "source": [
    "# Store our model\n",
    "software_spec_uid=client.software_specifications.get_id_by_name('spark-mllib_2.4')\n",
    "model_props = {\n",
    "               client.repository.ModelMetaNames.NAME: \"Trading Customer Churn Prediction Model\",\n",
    "               client.repository.ModelMetaNames.TYPE: 'mllib_2.4',\n",
    "               client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "               client.repository.ModelMetaNames.INPUT_DATA_SCHEMA: {'id': '1', 'type': 'struct', 'fields': [\n",
    "                   {'name': 'ID', 'type': 'double', 'nullable': False, 'metadata': {}}, \n",
    "                   {'name': 'GENDER', 'type': 'str', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'STATUS', 'type': 'str', 'nullable': False, 'metadata': {}}, \n",
    "                   {'name': 'CHILDREN', 'type': 'double', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'ESTINCOME', 'type': 'double', 'nullable': False, 'metadata': {}}, \n",
    "                   {'name': 'HOMEOWNER', 'type': 'str', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'AGE', 'type': 'double', 'nullable': False, 'metadata': {}}, \n",
    "                   {'name': 'TOTALDOLLARVALUETRADED', 'type': 'double', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'TOTALUNITSTRADED', 'type': 'double', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'LARGESTSINGLETRANSACTION', 'type': 'double', 'nullable': False, 'metadata': {}}, \n",
    "                   {'name': 'SMALLESTSINGLETRANSACTION', 'type': 'double', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'PERCENTCHANGECALCULATION', 'type': 'double', 'nullable': False, 'metadata': {}}, \n",
    "                   {'name': 'DAYSSINCELASTLOGIN', 'type': 'double', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'DAYSSINCELASTTRADE', 'type': 'double', 'nullable': False, 'metadata': {}}, \n",
    "                   {'name': 'NETREALIZEDGAINS_YTD', 'type': 'double', 'nullable': False, 'metadata': {}},\n",
    "                   {'name': 'NETREALIZEDLOSSES_YTD', 'type': 'double', 'nullable': False, 'metadata': {}}\n",
    "               ]}}\n",
    "published_model = client.repository.store_model(model=model, pipeline=pipeline, meta_props=model_props, training_data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d4d94c9f1fe4fd98d3254c7cc873d0c"
   },
   "outputs": [],
   "source": [
    "# new list of models\n",
    "client.repository.list_models()\n",
    "\n",
    "# get UID of our just stored model\n",
    "model_uid = client.repository.get_model_uid(published_model)\n",
    "print(\"Model id: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "590eac1c8c8a4b8f8d5dfa45346a42bf"
   },
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "        client.deployments.ConfigurationMetaNames.NAME: \"Trading Customer Churn Deployment\",\n",
    "        client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    "created_deployment = client.deployments.create(artifact_uid=model_uid , meta_props=meta_props)\n",
    "\n",
    "# new list of deployments\n",
    "client.deployments.list()\n",
    "\n",
    "\n",
    "# get UID of our new deployment\n",
    "deployment_uid = client.deployments.get_uid(created_deployment)\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47a3a66cd63f4e8a822934484b06fee4"
   },
   "outputs": [],
   "source": [
    "print(created_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5b9ff0f948f4c3cae22d3a8156984c5"
   },
   "outputs": [],
   "source": [
    "# get the scoring endpoint (deployment href) for the deployed WML model\n",
    "deployment_href = client.deployments.get_href(created_deployment)\n",
    "print(deployment_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "935bc93203a74f289da9836d2ae5ff51"
   },
   "outputs": [],
   "source": [
    "# get the deployment id for the deployed WML model\n",
    "deployment_id = client.deployments.get_uid(created_deployment)\n",
    "print(deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "307a919b1bbe45d39e77a347e6618b1e"
   },
   "outputs": [],
   "source": [
    "# test the model using an array of values\n",
    "import json\n",
    "values = [4,\"F\",\"M\",2,52004,\"N\",60,5030,23,1257,125,3,1,1,1000,0]\n",
    "fields = [\"ID\", \"GENDER\", \"STATUS\",\"CHILDREN\",\"ESTINCOME\",\"HOMEOWNER\",\"AGE\",\"TOTALDOLLARVALUETRADED\",\"TOTALUNITSTRADED\",\"LARGESTSINGLETRANSACTION\",\"SMALLESTSINGLETRANSACTION\",\"PERCENTCHANGECALCULATION\",\"DAYSSINCELASTLOGIN\",\"DAYSSINCELASTTRADE\",\"NETREALIZEDGAINS_YTD\",\"NETREALIZEDLOSSES_YTD\"]\n",
    "scoring_payload = {client.deployments.ScoringMetaNames.INPUT_DATA: [{\"fields\": fields, \"values\": [values]}]}\n",
    "print(json.dumps(scoring_payload, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c1800f1338b44db92deaa8abbcdf5c6"
   },
   "outputs": [],
   "source": [
    "# score the model by calling the WML service with the user provided data\n",
    "predictions = client.deployments.score(deployment_id, scoring_payload)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92840a6566ae4eb887364f45fac95e3d"
   },
   "source": [
    "### Save the test data as files so that they can be added as assets to your IBM Cloud Pak for Data project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c438b042dcc47c285f066e829ff262c"
   },
   "outputs": [],
   "source": [
    "# Write the test data without label to a .csv so that we can later use it for batch scoring\n",
    "write_score_CSV=test.toPandas().drop(['CHURNRISK'], axis=1)\n",
    "write_score_CSV.to_csv('/project_data/data_asset/TradingCustomerSparkMLBatchScore.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da136da21bf2421185ae887f97ca4ea4"
   },
   "outputs": [],
   "source": [
    "# Write the test data to a .csv so that we can later use it for evaluation\n",
    "write_eval_CSV=test.toPandas()\n",
    "write_eval_CSV.to_csv('/project_data/data_asset/TradingCustomerSparkMLEval.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94e7359c-4795-4360-9e50-5c855710eb2d"
   },
   "source": [
    "<p><font size=-1 color=gray>\n",
    "&copy; Copyright 2018 IBM Corp. All Rights Reserved.\n",
    "<p>\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n",
    "except in compliance with the License. You may obtain a copy of the License at\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the\n",
    "License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "express or implied. See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "</font></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
